<h1 id="john-hopkins-practical-machine-learning-report">John Hopkins Practical Machine Learning Report</h1>
<h2 id="introduction">Introduction</h2>
<p>The project for this course is to use machine learning to predict the manner in which a group did excercise. The following objectives are to be met as part of this report: * Describe how you built your model * How you used cross validation * Why you made the choices you did</p>
<h3 id="project-setup">Project Setup</h3>
<p>First, include required libraries, create folders, and download files</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Include libraries</span>
<span class="kw">library</span>(caret)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create data folder if it does not exist</span>
dataFolder =<span class="st"> &quot;data&quot;</span>
if (!<span class="kw">file.exists</span>(dataFolder)) {
        <span class="kw">dir.create</span>(dataFolder)
}</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Download test files if they do not exist</span>
trainInput &lt;-<span class="st"> &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv&quot;</span>
testInput &lt;-<span class="st"> &quot;https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv&quot;</span>
trainDisk &lt;-<span class="st"> </span><span class="kw">file.path</span>(dataFolder,<span class="st">&quot;training.csv&quot;</span>)
testDisk &lt;-<span class="st"> </span><span class="kw">file.path</span>(dataFolder, <span class="st">&quot;test.csv&quot;</span>)

if (!<span class="kw">file.exists</span>(trainDisk)) {
        <span class="kw">download.file</span>(trainInput, <span class="dt">destfile =</span> trainDisk, <span class="dt">method =</span> <span class="st">&quot;curl&quot;</span>)
}

if (!<span class="kw">file.exists</span>(testDisk)) {
        <span class="kw">download.file</span>(testInput, <span class="dt">destfile =</span> testDisk, <span class="dt">method =</span> <span class="st">&quot;curl&quot;</span>)
}</code></pre>
<h3 id="prepare-data">Prepare Data</h3>
<p>Next we need to load, clean, and partition our data sets</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Read the downloaded csv files into data frames</span>
trainCsv &lt;-<span class="st"> </span><span class="kw">read.csv</span>(trainDisk)
testCsv &lt;-<span class="st"> </span><span class="kw">read.csv</span>(testDisk)

<span class="co"># Next I used View(trainCsv) and I see lots of NA Values. Lets remove those first.</span>
trainCsv &lt;-<span class="st"> </span>trainCsv[, <span class="kw">colSums</span>(<span class="kw">is.na</span>(trainCsv)) ==<span class="st"> </span><span class="dv">0</span>]
testCsv &lt;-<span class="st">  </span>testCsv[, <span class="kw">colSums</span>(<span class="kw">is.na</span>(testCsv)) ==<span class="st"> </span><span class="dv">0</span>]

<span class="co"># Again I used View(trainCsv) and there are some obvious columns that are not useful</span>
dropCol &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;user_name&quot;</span>, <span class="st">&quot;raw_timestamp_part_1&quot;</span>, <span class="st">&quot;raw_timestamp_part_2&quot;</span>, <span class="st">&quot;cvtd_timestamp&quot;</span>, <span class="st">&quot;new_window&quot;</span>, <span class="st">&quot;num_window&quot;</span>)
trainCsv &lt;-<span class="st"> </span>trainCsv[, -<span class="kw">which</span>(<span class="kw">names</span>(trainCsv) %in%<span class="st"> </span>dropCol)]
testCsv &lt;-<span class="st"> </span>testCsv[, -<span class="kw">which</span>(<span class="kw">names</span>(testCsv) %in%<span class="st"> </span>dropCol)]

<span class="co"># Even with this a Random Forest with 200 trees was still taking forever</span>
<span class="co"># so lets turn our classe into a factor and set it aside for a moment</span>
trainClasse &lt;-<span class="st"> </span><span class="kw">as.factor</span>(trainCsv$classe)

<span class="co"># Next lets strip out everything non-numeric</span>
trainCsv &lt;-<span class="st"> </span>trainCsv[, <span class="kw">sapply</span>(trainCsv, is.numeric)]
testCsv &lt;-<span class="st"> </span>testCsv[, <span class="kw">sapply</span>(testCsv, is.numeric)]

<span class="co"># Then put our classe back</span>
trainCsv$classe &lt;-<span class="st"> </span>trainClasse

<span class="co"># Finally partition the data</span>
<span class="kw">set.seed</span>(<span class="dv">19622</span>)
inTrain &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(trainCsv$classe, <span class="dt">p =</span> <span class="dv">3</span>/<span class="dv">4</span>)[[<span class="dv">1</span>]]
training &lt;-<span class="st"> </span>trainCsv[inTrain,]
testing &lt;-<span class="st"> </span>trainCsv[-inTrain,]</code></pre>
<h2 id="model-building">Model Building</h2>
<p>Next we are going to build three different models and then combine the models and see what accuracy we get from each scenario</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Random Forest</span>
mod_rf &lt;-<span class="st"> </span><span class="kw">train</span>(classe ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>)
<span class="co"># Boosted</span>
mod_gbm &lt;-<span class="st"> </span><span class="kw">train</span>(classe ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;gbm&quot;</span>, <span class="dt">verbose=</span><span class="ot">FALSE</span>)
<span class="co"># Latent allocation</span>
mod_lda &lt;-<span class="st"> </span><span class="kw">train</span>(classe ~<span class="st"> </span>., <span class="dt">data =</span> training, <span class="dt">method =</span> <span class="st">&quot;lda&quot;</span>)

<span class="co"># Run predictors</span>
pred_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(mod_rf, testing)
pred_gbm &lt;-<span class="st"> </span><span class="kw">predict</span>(mod_gbm, testing)
pred_lda &lt;-<span class="st"> </span><span class="kw">predict</span>(mod_lda, testing)

<span class="co"># Combined</span>
predDF &lt;-<span class="st"> </span><span class="kw">data.frame</span>(pred_rf, pred_gbm, pred_lda, <span class="dt">classe =</span> testing$classe)
combModFit &lt;-<span class="st"> </span><span class="kw">train</span>(classe ~<span class="st"> </span>., <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="dt">data =</span> predDF)
combPred &lt;-<span class="st"> </span><span class="kw">predict</span>(combModFit, predDF)</code></pre>
<h3 id="model-comparisons">Model Comparisons</h3>
<p>Now that our models are built, we can compare the results.</p>
<pre class="sourceCode r"><code class="sourceCode r">results &lt;-<span class="st"> </span><span class="kw">resamples</span>(<span class="kw">list</span>(<span class="dt">rf=</span>mod_rf, <span class="dt">gbm=</span>mod_gbm, <span class="dt">lda=</span>mod_lda, <span class="dt">comb=</span>combModFit))
<span class="kw">summary</span>(results)</code></pre>
<pre><code>## 
## Call:
## summary.resamples(object = results)
## 
## Models: rf, gbm, lda, comb 
## Number of resamples: 25 
## 
## Accuracy 
##           Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf   0.9992693 0.9998129 0.9998151 0.9997863 0.9998177 1.0000000    0
## gbm  0.9992631 0.9996291 0.9998142 0.9997342 0.9998170 1.0000000    0
## lda  0.9576887 0.9613146 0.9621581 0.9627126 0.9649734 0.9683882    0
## comb 0.9994490 1.0000000 1.0000000 0.9999780 1.0000000 1.0000000    0
## 
## Kappa 
##           Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA&#39;s
## rf   0.9990771 0.9997632 0.9997663 0.9997298 0.9997694 1.0000000    0
## gbm  0.9990680 0.9995310 0.9997655 0.9996637 0.9997682 1.0000000    0
## lda  0.9465013 0.9512403 0.9522315 0.9529067 0.9557554 0.9600779    0
## comb 0.9993036 1.0000000 1.0000000 0.9999721 1.0000000 1.0000000    0</code></pre>
<p>As you can see, the predicted accuracy of Random Forest and Boosted are nearly identical. By combining all three, we can get an insignificantly higher accuracy.</p>
<p>Here you can see the results as a box plot:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">bwplot</span>(results)</code></pre>
<div class="figure">
<img src="report_files/figure-markdown_github-ascii_identifiers/boxplot-1.png" />
</div>
<p>Here are the results as a dot plot</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">dotplot</span>(results)</code></pre>
<div class="figure">
<img src="report_files/figure-markdown_github-ascii_identifiers/dotplot-1.png" />
</div>
<h3 id="model-selection">Model Selection</h3>
<p>As the results of Random Forest, Boosted, and Combined were all above 99%, I am going to select the Random Forest model. Let's go ahead and re-build the model with five fold cross validation and a larger forest.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Cross validation</span>
cv &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;cv&quot;</span>, <span class="dv">5</span>)
mod_rf &lt;-<span class="st"> </span><span class="kw">train</span>(classe ~., <span class="dt">data=</span>training, <span class="dt">method=</span><span class="st">&quot;rf&quot;</span>, <span class="dt">trControl=</span>cv, <span class="dt">ntree=</span><span class="dv">250</span>)
<span class="co"># View results</span>
mod_rf</code></pre>
<pre><code>## Random Forest 
## 
## 14718 samples
##    53 predictor
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (5 fold) 
## Summary of sample sizes: 11773, 11774, 11775, 11774, 11776 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.9982334  0.9977655
##   27    0.9997961  0.9997422
##   53    0.9996603  0.9995703
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 27.</code></pre>
<p>Next, let's estimate against the validation set.</p>
<pre class="sourceCode r"><code class="sourceCode r">pred_rf &lt;-<span class="st"> </span><span class="kw">predict</span>(mod_rf, testing)
<span class="kw">confusionMatrix</span>(testing$classe, pred_rf)</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1395    0    0    0    0
##          B    0  949    0    0    0
##          C    0    0  855    0    0
##          D    0    0    0  804    0
##          E    0    0    0    0  901
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.9992, 1)
##     No Information Rate : 0.2845     
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
##                                      
##                   Kappa : 1          
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   1.0000   1.0000   1.0000   1.0000
## Specificity            1.0000   1.0000   1.0000   1.0000   1.0000
## Pos Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Neg Pred Value         1.0000   1.0000   1.0000   1.0000   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1639   0.1837
## Detection Rate         0.2845   0.1935   0.1743   0.1639   0.1837
## Detection Prevalence   0.2845   0.1935   0.1743   0.1639   0.1837
## Balanced Accuracy      1.0000   1.0000   1.0000   1.0000   1.0000</code></pre>
<p>Finally, we can see the overall estimated accuracy for the Random Forest model:</p>
<pre class="sourceCode r"><code class="sourceCode r">accuracy &lt;-<span class="st"> </span><span class="kw">postResample</span>(pred_rf, testing$classe)
accuracy</code></pre>
<pre><code>## Accuracy    Kappa 
##        1        1</code></pre>
<p>And the expected out of sample error:</p>
<pre class="sourceCode r"><code class="sourceCode r">
outOfSampleError <- sum(pred_rf == testing$classe)/length(pred_rf)
</code></pre>
<h2 id="summary">Summary</h2>
<p>In conclusion, we went with the Random Forest model because: * It gave nearly the same accuracy as Boosted * Performed much faster than building and combinding with the other algorithims * With estimated accuracy of 99%, there is little need for improvement</p>
<p>Our final Random Forest model was built using five fold cross validation.</p>
